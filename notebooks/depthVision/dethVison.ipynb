{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-26T22:39:13.832894900Z",
     "start_time": "2023-11-26T22:39:13.450592200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import calendar\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''Here where made a lot of test and even more failed than worked. I did not deleted all the trial and error'''\n",
    "\n",
    "# Open the left and right video streams\n",
    "left_video_path = 'test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4'\n",
    "right_video_path = 'test_data_for_depth/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4'\n",
    "\n",
    "\n",
    "cap_left = cv2.VideoCapture(left_video_path)\n",
    "cap_right = cv2.VideoCapture(right_video_path)\n",
    "\n",
    "if not cap_left.isOpened() or not cap_right.isOpened():\n",
    "    print(\"Error: Could not open video files.\")\n",
    "    exit()\n",
    "\n",
    "# Create a VideoWriter for saving the disparity view as a video\n",
    "output_path = 'disparity_view.mp4'\n",
    "frame_width = int(cap_left.get(3))\n",
    "frame_height = int(cap_left.get(4))\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width * 2, frame_height))\n",
    "\n",
    "# Create a StereoBM object for disparity calculation\n",
    "stereo = cv2.StereoBM_create()\n",
    "\n",
    "stereo.setNumDisparities(7 * 16)\n",
    "stereo.setBlockSize(0 * 2 + 5)\n",
    "stereo.setPreFilterType(1)\n",
    "stereo.setPreFilterSize(7 * 2 + 5)\n",
    "stereo.setPreFilterCap(50)\n",
    "stereo.setTextureThreshold(40)\n",
    "stereo.setUniquenessRatio(0)\n",
    "stereo.setSpeckleRange(74)\n",
    "stereo.setSpeckleWindowSize(0 * 2)\n",
    "stereo.setDisp12MaxDiff(25)\n",
    "stereo.setMinDisparity(25)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read frames from the left and right video streams\n",
    "    ret_left, frame_left = cap_left.read()\n",
    "    ret_right, frame_right = cap_right.read()\n",
    "\n",
    "    if not ret_left or not ret_right:\n",
    "        break\n",
    "\n",
    "    # Convert frames to grayscale (assuming they are originally in color)\n",
    "    frame_left_gray = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)\n",
    "    frame_right_gray = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the disparity map\n",
    "    disparity = stereo.compute(frame_left_gray, frame_right_gray)\n",
    "\n",
    "    # Normalize the disparity map for better visualization\n",
    "    disparity_normalized = cv2.normalize(disparity, dst=None, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "    disparity_8u = disparity_normalized.astype(np.uint8)\n",
    "\n",
    "    # Apply the colormap to the CV_8UC1 disparity map\n",
    "    disparity_color = cv2.applyColorMap(disparity_8u, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Overlap the left and right frames to create a disparity view\n",
    "    overlap_image = cv2.addWeighted(frame_left, 0.5, frame_right, 0.5, 0)\n",
    "\n",
    "    # Concatenate the original frames and the disparity map horizontally\n",
    "    disparity_view = np.hstack((overlap_image, disparity_color))\n",
    "\n",
    "    # Write the disparity view frame to the output video\n",
    "    out.write(disparity_view)\n",
    "\n",
    "    # Display the disparity view in real-time\n",
    "    cv2.imshow('Disparity View', disparity_color)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture objects, the VideoWriter, and close the windows\n",
    "cap_left.release()\n",
    "cap_right.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://learnopencv.com/depth-perception-using-stereo-camera-python-c/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Headmap offset to big\n",
    "# Check for left and right camera IDs\n",
    "# These values can change depending on the system\n",
    "CamL_id = 2 # Camera ID for left camera\n",
    "CamR_id = 0 # Camera ID for right camera\n",
    "\n",
    "CamL= cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4')\n",
    "CamR= cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4')\n",
    "\n",
    "# Reading the mapping values for stereo image rectification\n",
    "cv_file = cv2.FileStorage(\"data/stereo_rectify_maps.xml\", cv2.FILE_STORAGE_READ)\n",
    "Left_Stereo_Map_x = cv_file.getNode(\"Left_Stereo_Map_x\").mat()\n",
    "Left_Stereo_Map_y = cv_file.getNode(\"Left_Stereo_Map_y\").mat()\n",
    "Right_Stereo_Map_x = cv_file.getNode(\"Right_Stereo_Map_x\").mat()\n",
    "Right_Stereo_Map_y = cv_file.getNode(\"Right_Stereo_Map_y\").mat()\n",
    "cv_file.release()\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('disp',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('disp',600,600)\n",
    "\n",
    "cv2.createTrackbar('numDisparities','disp',1,17,nothing)\n",
    "cv2.createTrackbar('blockSize','disp',5,50,nothing)\n",
    "cv2.createTrackbar('preFilterType','disp',1,1,nothing)\n",
    "cv2.createTrackbar('preFilterSize','disp',2,25,nothing)\n",
    "cv2.createTrackbar('preFilterCap','disp',5,62,nothing)\n",
    "cv2.createTrackbar('textureThreshold','disp',10,100,nothing)\n",
    "cv2.createTrackbar('uniquenessRatio','disp',15,100,nothing)\n",
    "cv2.createTrackbar('speckleRange','disp',0,100,nothing)\n",
    "cv2.createTrackbar('speckleWindowSize','disp',3,25,nothing)\n",
    "cv2.createTrackbar('disp12MaxDiff','disp',5,25,nothing)\n",
    "cv2.createTrackbar('minDisparity','disp',5,25,nothing)\n",
    "\n",
    "# Creating an object of StereoBM algorithm\n",
    "stereo = cv2.StereoBM_create()\n",
    "\n",
    "while True:\n",
    "\n",
    "  # Capturing and storing left and right camera images\n",
    "  retL, imgL= CamL.read()\n",
    "  retR, imgR= CamR.read()\n",
    "\n",
    "  # Proceed only if the frames have been captured\n",
    "  if retL and retR:\n",
    "    imgR_gray = cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)\n",
    "    imgL_gray = cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Applying stereo image rectification on the left image\n",
    "    Left_nice= cv2.remap(imgL_gray,\n",
    "              Left_Stereo_Map_x,\n",
    "              Left_Stereo_Map_y,\n",
    "              cv2.INTER_LANCZOS4,\n",
    "              cv2.BORDER_CONSTANT,\n",
    "              0)\n",
    "\n",
    "    # Applying stereo image rectification on the right image\n",
    "    Right_nice= cv2.remap(imgR_gray,\n",
    "              Right_Stereo_Map_x,\n",
    "              Right_Stereo_Map_y,\n",
    "              cv2.INTER_LANCZOS4,\n",
    "              cv2.BORDER_CONSTANT,\n",
    "              0)\n",
    "\n",
    "    # Updating the parameters based on the trackbar positions\n",
    "    numDisparities = cv2.getTrackbarPos('numDisparities','disp')*16\n",
    "    blockSize = cv2.getTrackbarPos('blockSize','disp')*2 + 5\n",
    "    preFilterType = cv2.getTrackbarPos('preFilterType','disp')\n",
    "    preFilterSize = cv2.getTrackbarPos('preFilterSize','disp')*2 + 5\n",
    "    preFilterCap = cv2.getTrackbarPos('preFilterCap','disp')\n",
    "    textureThreshold = cv2.getTrackbarPos('textureThreshold','disp')\n",
    "    uniquenessRatio = cv2.getTrackbarPos('uniquenessRatio','disp')\n",
    "    speckleRange = cv2.getTrackbarPos('speckleRange','disp')\n",
    "    speckleWindowSize = cv2.getTrackbarPos('speckleWindowSize','disp')*2\n",
    "    disp12MaxDiff = cv2.getTrackbarPos('disp12MaxDiff','disp')\n",
    "    minDisparity = cv2.getTrackbarPos('minDisparity','disp')\n",
    "\n",
    "    # Setting the updated parameters before computing disparity map\n",
    "    stereo.setNumDisparities(numDisparities)\n",
    "    stereo.setBlockSize(blockSize)\n",
    "    stereo.setPreFilterType(preFilterType)\n",
    "    stereo.setPreFilterSize(preFilterSize)\n",
    "    stereo.setPreFilterCap(preFilterCap)\n",
    "    stereo.setTextureThreshold(textureThreshold)\n",
    "    stereo.setUniquenessRatio(uniquenessRatio)\n",
    "    stereo.setSpeckleRange(speckleRange)\n",
    "    stereo.setSpeckleWindowSize(speckleWindowSize)\n",
    "    stereo.setDisp12MaxDiff(disp12MaxDiff)\n",
    "    stereo.setMinDisparity(minDisparity)\n",
    "\n",
    "    # Calculating disparity using the StereoBM algorithm\n",
    "    disparity = stereo.compute(Left_nice,Right_nice)\n",
    "    # NOTE: Code returns a 16bit signed single channel image,\n",
    "    # CV_16S containing a disparity map scaled by 16. Hence it\n",
    "    # is essential to convert it to CV_32F and scale it down 16 times.\n",
    "\n",
    "    # Converting to float32\n",
    "    disparity = disparity.astype(np.float32)\n",
    "\n",
    "    # Scaling down the disparity values and normalizing them\n",
    "    disparity = (disparity/16.0 - minDisparity)/numDisparities\n",
    "\n",
    "    # Displaying the disparity map\n",
    "    cv2.imshow(\"disp\",disparity)\n",
    "\n",
    "    # Close window using esc key\n",
    "    if cv2.waitKey(1) == 27:\n",
    "      break\n",
    "\n",
    "  else:\n",
    "    CamL= cv2.VideoCapture(CamL_id)\n",
    "    CamR= cv2.VideoCapture(CamR_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import cv2\n",
    "\n",
    "# Open the left and right video streams\n",
    "left_video_path = 'test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4'\n",
    "right_video_path = 'test_data_for_depth/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4'\n",
    "\n",
    "cap_left = cv2.VideoCapture(left_video_path)\n",
    "cap_right = cv2.VideoCapture(right_video_path)\n",
    "\n",
    "if not cap_left.isOpened() or not cap_right.isOpened():\n",
    "    print(\"Error: Could not open video files.\")\n",
    "    exit()\n",
    "\n",
    "# Get the frame width and height\n",
    "frame_width = int(cap_left.get(3))\n",
    "frame_height = int(cap_left.get(4))\n",
    "\n",
    "# Specify the horizontal shift amount in pixels\n",
    "horizontal_shift = 100  # Adjust this value as needed\n",
    "\n",
    "while True:\n",
    "    # Read frames from the left and right video streams\n",
    "    ret_left, frame_left = cap_left.read()\n",
    "    ret_right, frame_right = cap_right.read()\n",
    "\n",
    "    if not ret_left or not ret_right:\n",
    "        break\n",
    "\n",
    "    # Shift the frame of the right video horizontally\n",
    "    if horizontal_shift > 0:\n",
    "        frame_right_shifted = frame_right[:, horizontal_shift:]\n",
    "    elif horizontal_shift < 0:\n",
    "        frame_right_shifted = frame_right[:, :horizontal_shift]\n",
    "    else:\n",
    "        frame_right_shifted = frame_right\n",
    "\n",
    "    # Resize frames if necessary (optional)\n",
    "    # frame_left = cv2.resize(frame_left, (640, 480))\n",
    "    # frame_right_shifted = cv2.resize(frame_right_shifted, (640, 480))\n",
    "\n",
    "    # Display the left and right frames side by side as a stereo view\n",
    "    stereo_view = cv2.hconcat([frame_left, frame_right_shifted])\n",
    "\n",
    "    # Show the stereo view in the window\n",
    "    cv2.imshow(\"Stereo View\", stereo_view)\n",
    "\n",
    "    # Press 'q' to exit the loop\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture objects and close the window\n",
    "cap_left.release()\n",
    "cap_right.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Left and write together\n",
    "# Capture video from left and right cameras (adjust the file paths)\n",
    "left_video = cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4')  # Adjust the index or file path as needed\n",
    "right_video = cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4')\n",
    "\n",
    "# Lists to store calibration image points and object points for both cameras\n",
    "left_image_points = []\n",
    "right_image_points = []\n",
    "object_points = []\n",
    "\n",
    "# Define the checkerboard pattern size (e.g., 9x6)\n",
    "pattern_size = (9, 6)\n",
    "\n",
    "# Generate a grid of 3D points for the calibration target\n",
    "objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "\n",
    "while True:\n",
    "    ret1, left_frame = left_video.read()\n",
    "    ret2, right_frame = right_video.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    # Convert frames to grayscale\n",
    "    left_gray = cv2.cvtColor(left_frame, cv2.COLOR_BGR2GRAY)\n",
    "    right_gray = cv2.cvtColor(right_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find checkerboard corners in both frames\n",
    "    left_ret, left_corners = cv2.findChessboardCorners(left_gray, pattern_size, None)\n",
    "    right_ret, right_corners = cv2.findChessboardCorners(right_gray, pattern_size, None)\n",
    "\n",
    "    if left_ret and right_ret:\n",
    "        # Store detected image points and object points\n",
    "        left_image_points.append(left_corners)\n",
    "        right_image_points.append(right_corners)\n",
    "        object_points.append(objp)\n",
    "\n",
    "# Perform camera calibration for left and right cameras\n",
    "left_ret, left_mtx, left_dist, _, _ = cv2.calibrateCamera(object_points, left_image_points, left_gray.shape[::-1], None, None)\n",
    "right_ret, right_mtx, right_dist, _, _ = cv2.calibrateCamera(object_points, right_image_points, right_gray.shape[::-1], None, None)\n",
    "\n",
    "# Perform stereo calibration\n",
    "stereo_ret, _, _, _, _, R, T, E, F = cv2.stereoCalibrate(\n",
    "    object_points, left_image_points, right_image_points, left_mtx, left_dist, right_mtx, right_dist,\n",
    "    left_gray.shape[::-1]\n",
    ")\n",
    "\n",
    "# Rectify the cameras using stereoRectify and initUndistortRectifyMap\n",
    "# Use R, T, E, and F obtained from stereo calibration\n",
    "# Capture frames from your stereo cameras and proceed with stereo vision processing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from matplotlib.pyplot import hsv\n",
    "\n",
    "cap_right =cv2.VideoCapture('depthVision/test_data_for_depth/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4')\n",
    "cap_left =cv2.VideoCapture('depthVision/test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4')\n",
    "\n",
    "frame_rate = 30\n",
    "B = 9\n",
    "f = 6\n",
    "alpha = 56.6\n",
    "\n",
    "count = -1\n",
    "\n",
    "while(True):\n",
    "    count += 1\n",
    "\n",
    "    ret_right, frame_right = cap_right.read()\n",
    "    ret_left, frame_left = cap_left.read()\n",
    "\n",
    "    if ret_right==False or ret_left==False:\n",
    "        break\n",
    "    else:\n",
    "        mask_right = hsv.add_HSV_filter(frame_right, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "def videoToImageConverter(source_path: str, output_path: str, name: str):\n",
    "    vidcap = cv2.VideoCapture(source_path)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    count = 0\n",
    "\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    while count < total_frames:\n",
    "        success, image = vidcap.read()\n",
    "\n",
    "        if count % int(fps) == 0:\n",
    "            if not image is None and not image.size == 0:\n",
    "                cv2.imwrite(f\"{output_path}/{name}_{count}.png\", image)  # save frame as PNG file\n",
    "            else:\n",
    "                print(f\"Skipping empty frame at count {count}\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    vidcap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cap = cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "FRAMERATE = 25\n",
    "\n",
    "\n",
    "\n",
    "# Function to convert H.265 to MP4\n",
    "def convert_h265_to_mp4(input_file):\n",
    "    input_file = os.path.abspath(input_file)\n",
    "    print(input_file)\n",
    "    output_file = input_file + \".mp4\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-framerate\", str(FRAMERATE),\n",
    "        \"-i\", input_file,\n",
    "        \"-c\", \"copy\",\n",
    "        output_file\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Converted {input_file} to {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting {input_file}: {e}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "FRAMERATE = 25\n",
    "\n",
    "# Function to convert H.265 to MP4\n",
    "def convert_h265_to_mp4(input_file):\n",
    "\n",
    "    input_file = os.path.abspath(input_file)\n",
    "\n",
    "\n",
    "    output_file = input_file + \".mp4\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-framerate\", str(FRAMERATE),\n",
    "        \"-i\", input_file,\n",
    "        \"-c\", \"copy\",\n",
    "        output_file\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Converted {input_file} to {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error converting {input_file}: {e}\")\n",
    "\n",
    "# Loop through directories and files\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".h265\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            convert_h265_to_mp4(file_path)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "convert_h265_to_mp4('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cap = cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'X265')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (640,480))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        out.write(frame)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from time import sleep\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "# If the input is the camera, pass 0 instead of the video file name\n",
    "#cap = cv2.VideoCapture('test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265')\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('./test_data_for_depth/videos-2023-08-11 10_01_24.806689/leftCam.h265')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(total_frames)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  if ret == True:\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "  # Break the loop\n",
    "  else:\n",
    "    break\n",
    "\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Pfade zu den Videodateien für die linke und rechte Kamera\n",
    "left_video_path = 'D:\\\\BigBlock_01\\\\tt_video_data\\\\videos-2023-09-18 14_53_22.084271\\\\leftCam.h265.mp4'\n",
    "right_video_path = 'D:\\\\BigBlock_01\\\\tt_video_data\\\\videos-2023-09-18 14_53_22.084271\\\\rightCam.h265.mp4'\n",
    "\n",
    "\n",
    "# Öffnen der Videodateien\n",
    "CamL = cv2.VideoCapture(left_video_path)\n",
    "CamR = cv2.VideoCapture(right_video_path)\n",
    "\n",
    "# Pfad zur Ausgabedatei für die Disparitätskarte\n",
    "output_path = 'disparity_view.mp4'\n",
    "\n",
    "# Breite und Höhe der Videoframes\n",
    "frame_width = int(CamL.get(3))\n",
    "frame_height = int(CamL.get(4))\n",
    "\n",
    "# Erstellen des VideoWriters für die Ausgabedatei\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), 30, (frame_width * 2, frame_height))\n",
    "\n",
    "# Lesen der Mapping-Werte für die stereo Bildentzerrung\n",
    "cv_file = cv2.FileStorage(\"data/stereo_rectify_maps.xml\", cv2.FILE_STORAGE_READ)\n",
    "Left_Stereo_Map_x = cv_file.getNode(\"Left_Stereo_Map_x\").mat()\n",
    "Left_Stereo_Map_y = cv_file.getNode(\"Left_Stereo_Map_y\").mat()\n",
    "Right_Stereo_Map_x = cv_file.getNode(\"Right_Stereo_Map_x\").mat()\n",
    "Right_Stereo_Map_y = cv_file.getNode(\"Right_Stereo_Map_y\").mat()\n",
    "cv_file.release()\n",
    "\n",
    "# Erstellen eines StereoBM-Objekts\n",
    "stereo = cv2.StereoBM_create()\n",
    "\n",
    "while True:\n",
    "    # Erfassen und Speichern der Bilder von linker und rechter Kamera\n",
    "    retL, imgL = CamL.read()\n",
    "    retR, imgR = CamR.read()\n",
    "\n",
    "    if not retL or not retR:\n",
    "        break\n",
    "\n",
    "    # Umwandeln in Graustufen\n",
    "    imgR_gray = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "    imgL_gray = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Anwenden der stereo Bildentzerrung auf das linke Bild\n",
    "    Left_nice = cv2.remap(imgL_gray,\n",
    "                          Left_Stereo_Map_x,\n",
    "                          Left_Stereo_Map_y,\n",
    "                          cv2.INTER_LANCZOS4,\n",
    "                          cv2.BORDER_CONSTANT,\n",
    "                          0)\n",
    "\n",
    "    # Anwenden der stereo Bildentzerrung auf das rechte Bild\n",
    "    Right_nice = cv2.remap(imgR_gray,\n",
    "                           Right_Stereo_Map_x,\n",
    "                           Right_Stereo_Map_y,\n",
    "                           cv2.INTER_LANCZOS4,\n",
    "                           cv2.BORDER_CONSTANT,\n",
    "                           0)\n",
    "\n",
    "    # Setzen der Parameter für die Berechnung der Disparitätskarte\n",
    "    stereo.setNumDisparities(7 * 16)\n",
    "    stereo.setBlockSize(0 * 2 + 5)\n",
    "    stereo.setPreFilterType(1)\n",
    "    stereo.setPreFilterSize(7 * 2 + 5)\n",
    "    stereo.setPreFilterCap(50)\n",
    "    stereo.setTextureThreshold(40)\n",
    "    stereo.setUniquenessRatio(0)\n",
    "    stereo.setSpeckleRange(74)\n",
    "    stereo.setSpeckleWindowSize(0 * 2)\n",
    "    stereo.setDisp12MaxDiff(25)\n",
    "    stereo.setMinDisparity(25)\n",
    "\n",
    "    # Berechnung der Disparitätskarte\n",
    "    disparity = stereo.compute(Left_nice, Right_nice)\n",
    "\n",
    "    # Normalisieren und Skalieren der Disparitätskarte für die Darstellung\n",
    "    disparity_normalized = cv2.normalize(disparity, dst=None, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "    disparity_8u = disparity_normalized.astype(np.uint8)\n",
    "\n",
    "    # Anwenden einer Colormap auf die CV_8UC1 Disparitätskarte\n",
    "    disparity_color = cv2.applyColorMap(disparity_8u, cv2.COLORMAP_JET)\n",
    "\n",
    "    disparity = disparity_color.astype(np.float32)\n",
    "\n",
    "    # Skalieren auf den Bereich [0, 1]\n",
    "    disparity = (disparity / 255.0)\n",
    "\n",
    "    # Schreiben des Frames in die Ausgabedatei\n",
    "    out_frame = np.hstack((imgL, disparity_color))\n",
    "    out.write(disparity)\n",
    "    cv2.imshow(\"disp\", disparity)\n",
    "\n",
    "# Freigeben der VideoWriter-Ressourcen\n",
    "out.release()\n",
    "\n",
    "# Freigeben der VideoCapture-Ressourcen\n",
    "CamL.release()\n",
    "CamR.release()\n",
    "\n",
    "# Zerstören aller offenen Fenster\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Disparity-View Video wurde erfolgreich erstellt.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Pfade zu den Videodateien für die linke und rechte Kamera\n",
    "left_video_path = 'data/videos-2023-08-11 10_01_24.806689/leftCam.h265.mp4'\n",
    "right_video_path = 'data/videos-2023-08-11 10_01_24.806689/rightCam.h265.mp4'\n",
    "\n",
    "# Öffnen der Videodateien\n",
    "CamL = cv2.VideoCapture(left_video_path)\n",
    "CamR = cv2.VideoCapture(right_video_path)\n",
    "\n",
    "# Pfad zur Ausgabedatei für die Disparitätskarte\n",
    "#\n",
    "output_path = 'disparity_view.mp4'\n",
    "\n",
    "# Breite und Höhe der Videoframes\n",
    "#\n",
    "frame_width = int(CamL.get(3))\n",
    "#\n",
    "frame_height = int(CamL.get(4))\n",
    "\n",
    "# Create a VideoWriter for the output video\n",
    "#\n",
    "out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 30, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Capture and store frames from the left and right cameras\n",
    "    retL, imgL = CamL.read()\n",
    "    retR, imgR = CamR.read()\n",
    "\n",
    "    if not retL or not retR:\n",
    "        break\n",
    "\n",
    "    # Convert frames to grayscale\n",
    "    imgR_gray = cv2.cvtColor(imgR, cv2.COLOR_BGR2GRAY)\n",
    "    imgL_gray = cv2.cvtColor(imgL, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply stereo image rectification to the left image\n",
    "    Left_nice = cv2.remap(imgL_gray,\n",
    "                          Left_Stereo_Map_x,\n",
    "                          Left_Stereo_Map_y,\n",
    "                          cv2.INTER_LANCZOS4,\n",
    "                          cv2.BORDER_CONSTANT,\n",
    "                          0)\n",
    "\n",
    "    # Apply stereo image rectification to the right image\n",
    "    Right_nice = cv2.remap(imgR_gray,\n",
    "                           Right_Stereo_Map_x,\n",
    "                           Right_Stereo_Map_y,\n",
    "                           cv2.INTER_LANCZOS4,\n",
    "                           cv2.BORDER_CONSTANT,\n",
    "                           0)\n",
    "\n",
    "    # Set the parameters for computing the disparity map\n",
    "    # ... (Previous code)\n",
    "\n",
    "    # Compute the disparity map\n",
    "    disparity = stereo.compute(Left_nice, Right_nice)\n",
    "\n",
    "    # Normalize and scale the disparity map for visualization\n",
    "    disparity_normalized = cv2.normalize(disparity, dst=None, beta=0, alpha=255, norm_type=cv2.NORM_MINMAX)\n",
    "    disparity_8u = disparity_normalized.astype(np.uint8)\n",
    "\n",
    "    # Apply a colormap to the CV_8UC1 disparity map\n",
    "    disparity_color = cv2.applyColorMap(disparity_8u, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Convert to float32 and scale to [0, 1]\n",
    "    disparity = disparity_color.astype(np.float32) / 255.0\n",
    "\n",
    "    # Write the disparity map to the output video\n",
    "    out.write(disparity)\n",
    "\n",
    "    # Display the disparity map\n",
    "    cv2.imshow(\"Disparity Map\", disparity)\n",
    "\n",
    "    # Close the window using the 'Esc' key\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "# Release VideoWriter and VideoCapture resources\n",
    "out.release()\n",
    "CamL.release()\n",
    "CamR.release()\n",
    "\n",
    "# Close all open windows\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Disparity-View Video has been successfully created.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
