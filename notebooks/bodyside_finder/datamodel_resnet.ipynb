{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:47.635914400Z",
     "start_time": "2023-12-08T07:01:44.706094800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms\n",
    "from torchvision.models import ResNet152_Weights\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import os\n",
    "from os import path\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:48.577436100Z",
     "start_time": "2023-12-08T07:01:48.572887800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:49.387004Z",
     "start_time": "2023-12-08T07:01:49.367567900Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dataset = '20_11_2023_20_33_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:51.661820500Z",
     "start_time": "2023-12-08T07:01:51.644270600Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_path(timestamp: str):\n",
    "    abs_path = os.getcwd()\n",
    "    two_up =  path.abspath(path.join(abs_path ,\"../..\"))\n",
    "    return path.join(two_up, 'data', f'{os.path.basename(abs_path)}', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:56.338529100Z",
     "start_time": "2023-12-08T07:01:56.319171500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Pirmin.000\\\\PycharmProjects\\\\IGP\\\\data\\\\bodyside_finder\\\\20_11_2023_20_33_30'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:56.891969600Z",
     "start_time": "2023-12-08T07:01:56.795494400Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms_wt = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.485, 0.456, 0.406],\n",
    "        [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:57.244007100Z",
     "start_time": "2023-12-08T07:01:57.020756200Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m orig_set \u001B[38;5;241m=\u001B[39m datasets\u001B[38;5;241m.\u001B[39mImageFolder(\n\u001B[0;32m      2\u001B[0m     root\u001B[38;5;241m=\u001B[39mdataset_path(input_dataset),\n\u001B[0;32m      3\u001B[0m     transform\u001B[38;5;241m=\u001B[39mtransforms_wt\n\u001B[0;32m      4\u001B[0m )\n\u001B[1;32m----> 5\u001B[0m data, label \u001B[38;5;241m=\u001B[39m \u001B[43morig_set\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      6\u001B[0m transform_test \u001B[38;5;241m=\u001B[39m T\u001B[38;5;241m.\u001B[39mToPILImage()\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(transform_test(data))\n",
      "File \u001B[1;32m~\\PycharmProjects\\IGP\\testvenv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:228\u001B[0m, in \u001B[0;36mDatasetFolder.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Any, Any]:\n\u001B[0;32m    221\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m        index (int): Index\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;124;03m        tuple: (sample, target) where target is class_index of the target class.\u001B[39;00m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 228\u001B[0m     path, target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msamples\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    229\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader(path)\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "orig_set = datasets.ImageFolder(\n",
    "    root=dataset_path(input_dataset),\n",
    "    transform=transforms_wt\n",
    ")\n",
    "data, label = orig_set[100]\n",
    "transform_test = T.ToPILImage()\n",
    "plt.imshow(transform_test(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:57.406252Z",
     "start_time": "2023-12-08T07:01:57.270014900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['left', 'middle', 'right']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:57.774368400Z",
     "start_time": "2023-12-08T07:01:57.754106100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:01:58.818689800Z",
     "start_time": "2023-12-08T07:01:58.699038400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "data, label = orig_set[0]\n",
    "print(data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:02:01.432045900Z",
     "start_time": "2023-12-08T07:02:01.411692300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "data_loader = DataLoader(orig_set, batch_size=len(orig_set), shuffle=True)\n",
    "\n",
    "# Define the dataset size\n",
    "dataset_size = len(orig_set)\n",
    "\n",
    "# Calculate the sizes for training, validation, and test sets\n",
    "train_size = int(0.6 * dataset_size)\n",
    "val_size = int(0.2 * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_set, val_set, test_set = random_split(orig_set, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:02:43.343706Z",
     "start_time": "2023-12-08T07:02:43.307916Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m val_data, val_label \u001B[38;5;241m=\u001B[39m \u001B[43mval_set\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(val_data\u001B[38;5;241m.\u001B[39msize())\n",
      "File \u001B[1;32m~\\PycharmProjects\\IGP\\testvenv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:356\u001B[0m, in \u001B[0;36mSubset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(idx, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m idx]]\n\u001B[1;32m--> 356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m]\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "val_data, val_label = val_set[0]\n",
    "print(val_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:02:55.034668300Z",
     "start_time": "2023-12-08T07:02:54.947119900Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m transform \u001B[38;5;241m=\u001B[39m T\u001B[38;5;241m.\u001B[39mToPILImage()\n\u001B[1;32m----> 2\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(transform(\u001B[43mval_data\u001B[49m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "transform = T.ToPILImage()\n",
    "plt.imshow(transform(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:01.600387600Z",
     "start_time": "2023-12-08T07:03:01.579696600Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:02.149470Z",
     "start_time": "2023-12-08T07:03:02.016827600Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\IGP\\testvenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:349\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m--> 349\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    351\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\IGP\\testvenv\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:140\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:02.612707800Z",
     "start_time": "2023-12-08T07:03:02.515234400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:08.680754800Z",
     "start_time": "2023-12-08T07:03:07.256891300Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)\n",
    "\n",
    "#print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T22:32:36.967519300Z",
     "start_time": "2023-11-10T22:32:32.363159Z"
    }
   },
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 7)\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:13.552516300Z",
     "start_time": "2023-12-08T07:03:12.993693900Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(model.fc.in_features, 2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(2048,1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(1024,500),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(500,3)\n",
    ")\n",
    "#print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:14.246986900Z",
     "start_time": "2023-12-08T07:03:14.229953100Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:15.183716500Z",
     "start_time": "2023-12-08T07:03:14.919312700Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Pirmin.000\\\\PycharmProjects\\\\IGP\\\\notebooks\\\\bodyside_finder'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:24.389113900Z",
     "start_time": "2023-12-08T07:03:24.368048Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-08T07:05:35.858348900Z",
     "start_time": "2023-12-08T07:05:35.835772500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-12-08T07:03:36.748980500Z",
     "start_time": "2023-12-08T07:03:31.298549700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Pirmin.000\\PycharmProjects\\IGP\\testvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mframework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FrameworkLogger\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mframework\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmain_func\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m main_train_func\n\u001B[1;32m---> 10\u001B[0m input_args \u001B[38;5;241m=\u001B[39m [train_loader, \u001B[43mval_loader\u001B[49m, model, criterion, optimizer, exp_lr_scheduler, device]\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Modell trainieren\u001B[39;00m\n\u001B[0;32m     13\u001B[0m logger \u001B[38;5;241m=\u001B[39m FrameworkLogger(\u001B[38;5;241m5\u001B[39m, model, main_train_func, input_args, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpirmin_bodyside_pytorch_resnet\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "sys.path.append(os.path.join(os.getcwd(), '../..'))\n",
    "\n",
    "from framework.framework import FrameworkLogger\n",
    "from framework.main_func import main_train_func\n",
    "\n",
    "input_args = [train_loader, val_loader, model, criterion, optimizer, exp_lr_scheduler, device]\n",
    "\n",
    "# Modell trainieren\n",
    "logger = FrameworkLogger(5, model, main_train_func, input_args, \"pirmin_bodyside_pytorch_resnet\")\n",
    "logger.train_model_pyt()\n",
    "#logger.generate_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_time = time.time()\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()/inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)/inputs.size(0)\n",
    "\n",
    "\n",
    "    exp_lr_scheduler.step()\n",
    "    train_epoch_loss = running_loss / len(train_loader)\n",
    "    train_epoch_acc = running_corrects / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in (val_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() / inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data) / inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = running_corrects.double() / len(val_loader)\n",
    "    print(f\"Epoch: {epoch}: Train: Loss: {train_epoch_loss:.4f} Acc: {train_epoch_acc:.4f} Val: Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Time:\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    return datetime.datetime.now().strftime(\"%d_%m_%Y_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_save_path(timestamp: str):\n",
    "    abs_path = os.getcwd()\n",
    "    two_up =  path.abspath(path.join(abs_path ,\"../..\"))\n",
    "    return path.join(two_up, 'models', f'{os.path.basename(abs_path)}', timestamp, f'model_{get_time()}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_save_path(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_path = model_save_path(input_dataset)\n",
    "\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-10T22:32:35.221517500Z"
    },
    "is_executing": true
   },
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_correct = 0.0\n",
    "for inputs, labels in test_loader:\n",
    "    model.eval()\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    predict_label = model(inputs)\n",
    "    _, predicted = torch.max(predict_label,1)\n",
    "    num_correct += (predicted == labels).float().sum()\n",
    "\n",
    "    accuracy = num_correct/(len(test_loader)*test_loader.batch_size)\n",
    "\n",
    "print(len(test_loader), test_loader.batch_size)\n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def print_grid():\n",
    "    inputs, classes = next(iter(test_loader))\n",
    "    out = torchvision.utils.make_grid(inputs)\n",
    "    class_names = orig_set.classes\n",
    "\n",
    "    outputs = model(inputs.to(device))\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    imshow(out, title=[class_names[x] for x in preds])\n",
    "\n",
    "print_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#starttime 11:55\n",
    "#endtime\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current timestamp\n",
    "timestamp = datetime.now()\n",
    "formatted_timestamp = timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(\"Formatted timestamp:\", formatted_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
